{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rfc_tfidf_binary_sklearn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEcSktu36z3amA80jvXioQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jefffish09/MachineLearning/blob/dev/Classification/binary/rfc_tfidf_binary_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q66l9SxX3AKD"
      },
      "source": [
        "References:\r\n",
        "\r\n",
        "* https://www.kaggle.com/onadegibert/sentiment-analysis-with-tfidf-and-random-forest\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unvS4vlfzZpv"
      },
      "source": [
        "import numpy as np\r\n",
        "from tensorflow.keras.datasets import imdb\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ_u1XFwz3E3"
      },
      "source": [
        "seed = 2021\r\n",
        "index_from = 3\r\n",
        "vocab_size = 5000\r\n",
        "max_len = 200"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vHxX-Mgz7rI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207d6649-7e52-43fd-9f62-696c6f6d6431"
      },
      "source": [
        "# Load the dataset\r\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size, index_from=index_from)\r\n",
        "\r\n",
        "# Restore original text from imdb dataset\r\n",
        "# https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\r\n",
        "word2idx = imdb.get_word_index()\r\n",
        "word2idx = {k: (v+index_from) for k, v in word2idx.items()}\r\n",
        "word2idx[\"<PAD>\"] = 0\r\n",
        "word2idx[\"<START>\"] = 1\r\n",
        "word2idx[\"<UNK>\"] = 2\r\n",
        "word2idx[\"<UNUSED>\"] = 3\r\n",
        "idx2word = {value: key for key,value in word2idx.items()}\r\n",
        "\r\n",
        "x_train_words = [\" \".join(idx2word[id] for id in sent) for sent in x_train]\r\n",
        "x_test_words = [\" \".join(idx2word[id] for id in sent) for sent in x_test]\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lUyp5iHz9dJ"
      },
      "source": [
        "tfidf_vec = TfidfVectorizer(\r\n",
        "    ngram_range=(1, 2),\r\n",
        "    max_df=0.95,\r\n",
        "    min_df=5,\r\n",
        "    max_features=vocab_size,\r\n",
        "    sublinear_tf=True\r\n",
        ")\r\n",
        "\r\n",
        "x_train_tfidf = tfidf_vec.fit_transform(x_train_words)\r\n",
        "x_test_tfidf = tfidf_vec.transform(x_test_words)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDU48PC9z_iY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ccba799-3cdd-4e1c-f98c-7170afe8fce6"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=seed, verbose=1)\r\n",
        "rf.fit(X=x_train_tfidf, y=y_train)\r\n",
        "\r\n",
        "preds = rf.predict(X=x_test_tfidf)\r\n",
        "report = classification_report(y_true=y_test, y_pred=preds, digits=4)\r\n",
        "print(report)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   25.0s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   54.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.5s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8390    0.8430    0.8410     12500\n",
            "           1     0.8422    0.8382    0.8402     12500\n",
            "\n",
            "    accuracy                         0.8406     25000\n",
            "   macro avg     0.8406    0.8406    0.8406     25000\n",
            "weighted avg     0.8406    0.8406    0.8406     25000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    1.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dke9iTMX2QFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90bc15c6-c8b9-4c97-d0f9-aeea4750bfff"
      },
      "source": [
        "scores = cross_val_score(rf, X=x_train_tfidf, y=y_train, cv=10, verbose=1)\r\n",
        "print(scores)\r\n",
        "print(scores.mean())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   22.3s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.6s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   46.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   46.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.5s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   46.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.5s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   46.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.6s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   21.7s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.0s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.8296 0.8532 0.8428 0.8384 0.844  0.8404 0.8348 0.844  0.8448 0.8268]\n",
            "0.83988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  7.9min finished\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}